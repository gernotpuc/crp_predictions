{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chronos import ChronosPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(train_series_dict,valid_series_dict):\n",
    "    train_series_tensors = {}\n",
    "    valid_series_tensors = {}\n",
    "    for key, ts in train_series_dict.items():\n",
    "        # Extract the numpy array from the TimeSeries object\n",
    "        # Assuming `ts.values()` returns the data array, call the method to get the data\n",
    "        data = ts.values()  # Notice the parentheses to call the method\n",
    "        \n",
    "        # Convert the numpy array to a PyTorch tensor\n",
    "        tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Add the tensor to the dictionary\n",
    "        train_series_tensors[key] = tensor\n",
    "\n",
    "\n",
    "    for key, ts in valid_series_dict.items():\n",
    "        # Extract the numpy array from the TimeSeries object\n",
    "        # Assuming `ts.values()` returns the data array, call the method to get the data\n",
    "        data = ts.values()  # Notice the parentheses to call the method\n",
    "        \n",
    "        # Convert the numpy array to a PyTorch tensor\n",
    "        tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Add the tensor to the dictionary\n",
    "        valid_series_tensors[key] = tensor\n",
    "        \n",
    "    return train_series_tensors, valid_series_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chronos_predict(train_series_dict,valid_series_dict):\n",
    "    train_series_tensors, valid_series_tensors = convert_to_tensors(train_series_dict,valid_series_dict)\n",
    "    pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-base\",\n",
    "    device_map=\"cuda\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    # Dictionary to store the forecasts for each time series\n",
    "    forecasts = {}\n",
    "\n",
    "    # Iterate over each time series in the dictionary\n",
    "    for key, context in train_series_tensors.items():\n",
    "        # Ensure the context is a 1D tensor or prepare it appropriately\n",
    "        # Here, we assume `context` is a 2D tensor (e.g., [time, features])\n",
    "        # Select the feature of interest (e.g., crp) if necessary\n",
    "        # Adjust the slicing based on the data structure\n",
    "        context = context[:, 0]  # Assuming first component is 'crp' and we want a 1D tensor\n",
    "        \n",
    "        # Make sure context is on the same device as the pipeline (if using CUDA or MPS)\n",
    "        #context = context.to(pipeline.device)\n",
    "\n",
    "        # Make forecasts with the given context\n",
    "        forecast = pipeline.predict(\n",
    "            context=context,\n",
    "            prediction_length=1,  # Specify the desired forecast length\n",
    "            num_samples=500,      # Specify the number of samples for probabilistic forecast\n",
    "        )\n",
    "\n",
    "        # Store the forecast result\n",
    "        forecasts[key] = forecast\n",
    "    evaluate_chronos(forecasts,valid_series_tensors)\n",
    "    return forecasts,valid_series_tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chronos(forecasts,valid_series_tensors):\n",
    "    # Initialize accumulators for the metrics\n",
    "    total_mae = 0\n",
    "    total_mse = 0\n",
    "    total_smape = 0\n",
    "    num_series = 0\n",
    "\n",
    "    for key, forecast in forecasts.items():\n",
    "        # Get the true values from valid_series_dict\n",
    "        true_values = valid_series_tensors[key]\n",
    "        last_value = true_values[-1]\n",
    "        \n",
    "\n",
    "        # Take the mean of the forecasts along the samples dimension (axis 1)\n",
    "        forecast_mean = forecast.mean(dim=1)\n",
    "        # Compute the absolute errors\n",
    "        absolute_errors = torch.abs(forecast_mean - last_value)\n",
    "        # Compute MAE for this time series\n",
    "        mae = absolute_errors.mean().item()\n",
    "        total_mae += mae\n",
    "        \n",
    "        # Compute MSE for this time series\n",
    "        mse = (absolute_errors ** 2).mean().item()\n",
    "        total_mse += mse\n",
    "        \n",
    "        # Compute SMAPE for this time series\n",
    "        denominator = (torch.abs(last_value) + torch.abs(forecast_mean)) / 2\n",
    "        smape = (absolute_errors / denominator).mean().item() * 100\n",
    "        total_smape += smape\n",
    "        \n",
    "        num_series += 1\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_mae = total_mae / num_series\n",
    "    overall_mse = total_mse / num_series\n",
    "    overall_rmse = torch.sqrt(torch.tensor(overall_mse)).item()\n",
    "    #overall_smape = total_smape / num_series\n",
    "\n",
    "    print(f'MAE: {overall_mae}')\n",
    "    print(f'MSE: {overall_mse}')\n",
    "    print(f'RMSE: {overall_rmse}')\n",
    "    #print(f'SMAPE: {overall_smape}%')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
