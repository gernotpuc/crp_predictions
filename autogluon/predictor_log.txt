Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'autogluon'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.10
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #202309061752 SMP Wed Sep 6 22:35:16 UTC 2023
CPU Count:          128
GPU Count:          1
Memory Avail:       964.74 GB / 1007.33 GB (95.8%)
Disk Space Avail:   13.01 GB / 29.36 GB (44.3%)
===================================================
Setting presets to: best_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAE,
 'freq': 'D',
 'hyperparameters': {'DLinearModel': {},
                     'DeepAR': {},
                     'PatchTSTModel': {},
                     'TemporalFusionTransformerModel': {},
                     'TiDE': {}},
 'known_covariates_names': [],
 'num_val_windows': 2,
 'prediction_length': 1,
 'quantile_levels': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'crp',
 'time_limit': 600,
 'verbosity': 3}

Provided train_data has 2151 rows, 398 time series. Median time series length is 6 (min=4, max=6). 
Time series in train_data are too short for chosen num_val_windows=2. Reducing num_val_windows to 1.
	Removing 146 short time series from train_data. Only series with length >= 6 will be used for training.
	After filtering, train_data has 1512 rows, 252 time series. Median time series length is 6 (min=6, max=6). 

Provided data contains following columns:
	target: 'crp'

AutoGluon will gauge predictive performance using evaluation metric: 'MAE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-08-09 11:43:52
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'TiDE', 'PatchTST', 'DLinear']
Training timeseries model TemporalFusionTransformer. Training for up to 100.0s of the 599.9s of remaining time.
	-4.2614       = Validation score (-MAE)
	86.31   s     = Training runtime
	0.22    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 102.6s of the 513.2s of remaining time.
	-4.7400       = Validation score (-MAE)
	48.81   s     = Training runtime
	0.15    s     = Validation (prediction) runtime
Training timeseries model TiDE. Training for up to 116.0s of the 464.2s of remaining time.
	-4.2762       = Validation score (-MAE)
	64.62   s     = Training runtime
	0.33    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 133.0s of the 399.1s of remaining time.
	-4.0006       = Validation score (-MAE)
	32.52   s     = Training runtime
	0.16    s     = Validation (prediction) runtime
Training timeseries model DLinear. Training for up to 183.2s of the 366.4s of remaining time.
	-4.2573       = Validation score (-MAE)
	25.15   s     = Training runtime
	0.16    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DLinear': 0.23, 'PatchTST': 0.57, 'TemporalFusionTransformer': 0.02, 'TiDE': 0.17}
	-3.8421       = Validation score (-MAE)
	0.60    s     = Training runtime
	0.87    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'TiDE', 'PatchTST', 'DLinear', 'WeightedEnsemble']
Total runtime: 259.60 s
Best model: WeightedEnsemble
Best model score: -3.8421
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
